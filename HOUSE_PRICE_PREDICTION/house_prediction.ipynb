{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a machine learning model for predicting house prices using Python scikit-learn, and TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Loading Training and Test Data\n",
    "train_data_file = \"train.csv\"\n",
    "test_data_file = \"test.csv\"\n",
    "\n",
    "X = pd.read_csv(train_data_file, index_col='Id')\n",
    "X_test = pd.read_csv(test_data_file, index_col='Id')\n",
    "\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X.SalePrice              \n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the percentages of null value\n",
    "null_percent = X.isnull().sum()/X.shape[0]*100\n",
    "null_percent\n",
    "\n",
    "low_cardinality_columns = [col for col in X.columns if X[col].nunique() < 10 and X[col].dtype == \"object\"]\n",
    "num_columns = [col for col in X.columns if X[col].dtype in [\"int64\", \"float64\"]]\n",
    "\n",
    "required_columns = low_cardinality_columns + num_columns\n",
    "high_cardinality_columns = [col for col in X.columns if col not in required_columns]\n",
    "\n",
    "print(required_columns)\n",
    "print(\"Dropped_columns\", high_cardinality_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Pipeine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\")),\n",
    "    (\"one_hot_encoding\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, num_columns),\n",
    "        (\"categorical\", categorical_transformer, low_cardinality_columns)\n",
    "    ])\n",
    "\n",
    "def get_scores(n_estimators, learning_rate):\n",
    "    xgb_regressor_model = XGBRegressor(n_estimators=n_estimators,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       random_state=0,\n",
    "                                       n_jobs=4)\n",
    "\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"model_run\", xgb_regressor_model)\n",
    "    ])\n",
    "    \n",
    "    scores = -1 * cross_val_score(model_pipeline, X, y, cv=3, scoring=\"neg_mean_absolute_error\")\n",
    "    \n",
    "    return scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model and finding the appropriate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(8, 13):\n",
    "    for j in range(3):\n",
    "        results[(100*i, 0.04 + 0.01*j)] = get_scores(100*i, 0.04 + 0.01*j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "\n",
    "print(results)\n",
    "\n",
    "x_axis = list(each[0] for each in results)\n",
    "y_axis = list(each[1] for each in results)\n",
    "error = list(results[each] for each in results)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_axis, y_axis, error,\n",
    "           linewidths=1, alpha=.7,\n",
    "           edgecolor='k',\n",
    "           s = 200,\n",
    "           c=error)\n",
    "plt.show()\n",
    "\n",
    "min_mae = math.inf\n",
    "res = None\n",
    "for each in results:\n",
    "    if results[each] < min_mae:\n",
    "        min_mae = results[each]\n",
    "        res = each\n",
    "        \n",
    "print(res, min_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus the minimum error is n_esitimators = 900 and learning_rate = 0.04\n",
    "import pickle\n",
    "xgb_regressor_model = XGBRegressor(n_estimators=res[0],learning_rate=res[1],\n",
    "                                   random_state=0,\n",
    "                                   n_jobs=4)\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model_run\", xgb_regressor_model)\n",
    "])\n",
    "model_pipeline.fit(X, y)\n",
    "\n",
    "pickle.dump(model_pipeline, open(\"housing_price_model.pkl\", \"wb\"))\n",
    "\n",
    "preds = model_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = pd.DataFrame({\"Id\": X_test.index, \"SalePrice\": preds})\n",
    "output.to_csv(\"submission.csv\", index=False)\n",
    "output.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
